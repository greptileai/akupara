# LiteLLM Config
# @see https://docs.litellm.ai/docs/proxy/configs
# This serves as a template for the LiteLLM config file. You can freely change the model_list and model_group_alias to suit your needs.

model_list:
  - model_name: claude-*
    litellm_params:
      model: anthropic/claude-*
      api_base: 'os.environ/ANTHROPIC_BASE_URL'
      api_key: 'os.environ/ANTHROPIC_API_KEY'
  # - model_name: claude-* # For AWS Bedrock Claude models @see: https://docs.litellm.ai/docs/providers/bedrock#litellm-proxy-usage
  #   litellm_params:
  #     model: bedrock/anthropic.claude-* # Make sure this routes to the correct model
  #     aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
  #     aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
  #     aws_region_name: os.environ/AWS_REGION_NAME
  - model_name: gpt-*
    litellm_params:
      model: openai/gpt-*
      api_base: 'os.environ/OPENAI_BASE_URL'
      api_key: 'os.environ/OPENAI_API_KEY'
  - model_name: o*
    litellm_params:
      model: openai/o*
      api_base: 'os.environ/OPENAI_BASE_URL'
      api_key: 'os.environ/OPENAI_API_KEY'
  # - model_name: gpt-* # For Azure OpenAI models @see: https://docs.litellm.ai/docs/providers/azure/
  #   litellm_params:
  #     model: azure/gpt-*
  #     api_base: 'os.environ/AZURE_OPENAI_BASE_URL'
  #     api_key: 'os.environ/AZURE_OPENAI_API_KEY'
  #     api_version: 'os.environ/AZURE_OPENAI_API_VERSION'
  - model_name: text-embedding-*
    litellm_params:
      model: openai/text-embedding-*
      api_base: 'os.environ/OPENAI_BASE_URL'
      api_key: 'os.environ/OPENAI_API_KEY'
  # - model_name: titan-*
  #   litellm_params:
  #     model: bedrock/amazon.titan-* # @see: https://docs.litellm.ai/docs/providers/bedrock_embedding
  #     aws_access_key_id: os.environ/AWS_ACCESS_KEY_ID
  #     aws_secret_access_key: os.environ/AWS_SECRET_ACCESS_KEY
  #     aws_region_name: os.environ/AWS_REGION_NAME

litellm_settings:
  drop_params: True
  num_retries: 3
  allowed_fails: 3
  callbacks: ["custom_callbacks.proxy_handler_instance"] # Used for LLM Gateway's with OAuth token exchange, included in base image

router_settings:
  routing_strategy: simple-shuffle
  model_group_alias:
    {
      'memory-embeddings': 'text-embedding-3-small',
      'indexer-embeddings': 'text-embedding-3-small',
      'similarity-embeddings': 'text-embedding-3-small',
      'jobs-summarizer': 'gpt-5',
      'memory-clustering': 'claude-sonnet-4-20250514',
      'memory-learning': 'claude-sonnet-4-20250514',
      'review': 'claude-sonnet-4-20250514',
      'refiner': 'claude-sonnet-4-20250514',
      'summarizer': 'gpt-5-nano',
      'engine-mini': 'claude-sonnet-4-20250514',
      'claude-code': 'claude-sonnet-4-5',
    }
  num_retries: 2
  timeout: 60 # seconds

general_settings:
  forward_client_headers_to_llm_api: true
